{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ThirdAI's NeuralDB Aryan Patel and Mihir Panchal\n",
    "\n",
    "NeuralDB, as the name suggests, is a combination of a neural network and a database. It provides a high-level API for users to insert different types of files into it and search through the file contents with natural language queries. The neural network part of it enables semantic search while the database part of it stores the paragraphs of the files that are inserted into it.\n",
    "\n",
    "First, let's install the dependencies.\n",
    "\n",
    "\n",
    "#### This is a small project done by us in order to demonstrate the use of API and hone our skills while experiencing ThirdAI's API which is new for us we tried our best to get the best out of us Thank You."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: thirdai in g:\\anaconda\\lib\\site-packages (0.7.16)\n",
      "Requirement already satisfied: pandas>=1.2.0 in g:\\anaconda\\lib\\site-packages (from thirdai) (1.5.3)\n",
      "Requirement already satisfied: requests in g:\\anaconda\\lib\\site-packages (from thirdai) (2.28.1)\n",
      "Requirement already satisfied: numpy in g:\\anaconda\\lib\\site-packages (from thirdai) (1.23.5)\n",
      "Requirement already satisfied: typing-extensions in g:\\anaconda\\lib\\site-packages (from thirdai) (4.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in g:\\anaconda\\lib\\site-packages (from pandas>=1.2.0->thirdai) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in g:\\anaconda\\lib\\site-packages (from pandas>=1.2.0->thirdai) (2022.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in g:\\anaconda\\lib\\site-packages (from requests->thirdai) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in g:\\anaconda\\lib\\site-packages (from requests->thirdai) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in g:\\anaconda\\lib\\site-packages (from requests->thirdai) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in g:\\anaconda\\lib\\site-packages (from requests->thirdai) (2.1.1)\n",
      "Requirement already satisfied: six>=1.5 in g:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->thirdai) (1.16.0)\n",
      "Requirement already satisfied: thirdai[neural_db] in g:\\anaconda\\lib\\site-packages (0.7.16)\n",
      "Requirement already satisfied: typing-extensions in g:\\anaconda\\lib\\site-packages (from thirdai[neural_db]) (4.4.0)\n",
      "Requirement already satisfied: numpy in g:\\anaconda\\lib\\site-packages (from thirdai[neural_db]) (1.23.5)\n",
      "Requirement already satisfied: requests in g:\\anaconda\\lib\\site-packages (from thirdai[neural_db]) (2.28.1)\n",
      "Requirement already satisfied: pandas>=1.2.0 in g:\\anaconda\\lib\\site-packages (from thirdai[neural_db]) (1.5.3)\n",
      "Requirement already satisfied: python-docx in g:\\anaconda\\lib\\site-packages (from thirdai[neural_db]) (0.8.11)\n",
      "Requirement already satisfied: unidecode in g:\\anaconda\\lib\\site-packages (from thirdai[neural_db]) (1.2.0)\n",
      "Requirement already satisfied: bs4 in g:\\anaconda\\lib\\site-packages (from thirdai[neural_db]) (0.0.1)\n",
      "Requirement already satisfied: langchain in g:\\anaconda\\lib\\site-packages (from thirdai[neural_db]) (0.0.252)\n",
      "Requirement already satisfied: url-normalize in g:\\anaconda\\lib\\site-packages (from thirdai[neural_db]) (1.4.3)\n",
      "Requirement already satisfied: nltk in g:\\anaconda\\lib\\site-packages (from thirdai[neural_db]) (3.7)\n",
      "Requirement already satisfied: PyMuPDF in g:\\anaconda\\lib\\site-packages (from thirdai[neural_db]) (1.22.5)\n",
      "Requirement already satisfied: pydantic in g:\\anaconda\\lib\\site-packages (from thirdai[neural_db]) (1.10.12)\n",
      "Requirement already satisfied: PyTrie in g:\\anaconda\\lib\\site-packages (from thirdai[neural_db]) (0.4.0)\n",
      "Requirement already satisfied: trafilatura in g:\\anaconda\\lib\\site-packages (from thirdai[neural_db]) (1.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in g:\\anaconda\\lib\\site-packages (from pandas>=1.2.0->thirdai[neural_db]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in g:\\anaconda\\lib\\site-packages (from pandas>=1.2.0->thirdai[neural_db]) (2022.7)\n",
      "Requirement already satisfied: beautifulsoup4 in g:\\anaconda\\lib\\site-packages (from bs4->thirdai[neural_db]) (4.11.1)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in g:\\anaconda\\lib\\site-packages (from langchain->thirdai[neural_db]) (0.0.19)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in g:\\anaconda\\lib\\site-packages (from langchain->thirdai[neural_db]) (8.2.2)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in g:\\anaconda\\lib\\site-packages (from langchain->thirdai[neural_db]) (2.8.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in g:\\anaconda\\lib\\site-packages (from langchain->thirdai[neural_db]) (1.4.39)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in g:\\anaconda\\lib\\site-packages (from langchain->thirdai[neural_db]) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in g:\\anaconda\\lib\\site-packages (from langchain->thirdai[neural_db]) (0.5.14)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in g:\\anaconda\\lib\\site-packages (from langchain->thirdai[neural_db]) (3.8.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in g:\\anaconda\\lib\\site-packages (from langchain->thirdai[neural_db]) (6.0)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in g:\\anaconda\\lib\\site-packages (from langchain->thirdai[neural_db]) (1.2.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in g:\\anaconda\\lib\\site-packages (from requests->thirdai[neural_db]) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in g:\\anaconda\\lib\\site-packages (from requests->thirdai[neural_db]) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in g:\\anaconda\\lib\\site-packages (from requests->thirdai[neural_db]) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in g:\\anaconda\\lib\\site-packages (from requests->thirdai[neural_db]) (3.4)\n",
      "Requirement already satisfied: tqdm in g:\\anaconda\\lib\\site-packages (from nltk->thirdai[neural_db]) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in g:\\anaconda\\lib\\site-packages (from nltk->thirdai[neural_db]) (2022.7.9)\n",
      "Requirement already satisfied: joblib in g:\\anaconda\\lib\\site-packages (from nltk->thirdai[neural_db]) (1.1.1)\n",
      "Requirement already satisfied: click in g:\\anaconda\\lib\\site-packages (from nltk->thirdai[neural_db]) (8.0.4)\n",
      "Requirement already satisfied: lxml>=2.3.2 in g:\\anaconda\\lib\\site-packages (from python-docx->thirdai[neural_db]) (4.9.1)\n",
      "Requirement already satisfied: sortedcontainers in g:\\anaconda\\lib\\site-packages (from PyTrie->thirdai[neural_db]) (2.4.0)\n",
      "Requirement already satisfied: justext>=3.0.0 in g:\\anaconda\\lib\\site-packages (from trafilatura->thirdai[neural_db]) (3.0.0)\n",
      "Requirement already satisfied: courlan>=0.8.3 in g:\\anaconda\\lib\\site-packages (from trafilatura->thirdai[neural_db]) (0.9.3)\n",
      "Requirement already satisfied: htmldate>=1.3.2 in g:\\anaconda\\lib\\site-packages (from trafilatura->thirdai[neural_db]) (1.3.2)\n",
      "Requirement already satisfied: six in g:\\anaconda\\lib\\site-packages (from url-normalize->thirdai[neural_db]) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in g:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in g:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in g:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in g:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in g:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->thirdai[neural_db]) (22.1.0)\n",
      "Requirement already satisfied: langcodes>=3.3.0 in g:\\anaconda\\lib\\site-packages (from courlan>=0.8.3->trafilatura->thirdai[neural_db]) (3.3.0)\n",
      "Requirement already satisfied: tld>=0.13 in g:\\anaconda\\lib\\site-packages (from courlan>=0.8.3->trafilatura->thirdai[neural_db]) (0.13)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in g:\\anaconda\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db]) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in g:\\anaconda\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db]) (3.20.1)\n",
      "Requirement already satisfied: dateparser>=1.1.1 in g:\\anaconda\\lib\\site-packages (from htmldate>=1.3.2->trafilatura->thirdai[neural_db]) (1.1.8)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in g:\\anaconda\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->thirdai[neural_db]) (2.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in g:\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4->thirdai[neural_db]) (2.3.2.post1)\n",
      "Requirement already satisfied: colorama in g:\\anaconda\\lib\\site-packages (from click->nltk->thirdai[neural_db]) (0.4.6)\n",
      "Requirement already satisfied: tzlocal in g:\\anaconda\\lib\\site-packages (from dateparser>=1.1.1->htmldate>=1.3.2->trafilatura->thirdai[neural_db]) (5.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in g:\\anaconda\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db]) (22.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in g:\\anaconda\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain->thirdai[neural_db]) (0.4.3)\n",
      "Requirement already satisfied: tzdata in g:\\anaconda\\lib\\site-packages (from tzlocal->dateparser>=1.1.1->htmldate>=1.3.2->trafilatura->thirdai[neural_db]) (2023.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in g:\\anaconda\\lib\\site-packages (0.0.252)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in g:\\anaconda\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: numpy<2,>=1 in g:\\anaconda\\lib\\site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in g:\\anaconda\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in g:\\anaconda\\lib\\site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in g:\\anaconda\\lib\\site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in g:\\anaconda\\lib\\site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in g:\\anaconda\\lib\\site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in g:\\anaconda\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in g:\\anaconda\\lib\\site-packages (from langchain) (0.0.19)\n",
      "Requirement already satisfied: requests<3,>=2 in g:\\anaconda\\lib\\site-packages (from langchain) (2.28.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in g:\\anaconda\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in g:\\anaconda\\lib\\site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in g:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in g:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in g:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in g:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in g:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in g:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.1.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in g:\\anaconda\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in g:\\anaconda\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in g:\\anaconda\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in g:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in g:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in g:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in g:\\anaconda\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in g:\\anaconda\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (22.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in g:\\anaconda\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n",
      "Requirement already satisfied: openai in g:\\anaconda\\lib\\site-packages (0.27.8)\n",
      "Requirement already satisfied: tqdm in g:\\anaconda\\lib\\site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: requests>=2.20 in g:\\anaconda\\lib\\site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: aiohttp in g:\\anaconda\\lib\\site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in g:\\anaconda\\lib\\site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in g:\\anaconda\\lib\\site-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in g:\\anaconda\\lib\\site-packages (from requests>=2.20->openai) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in g:\\anaconda\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in g:\\anaconda\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in g:\\anaconda\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in g:\\anaconda\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in g:\\anaconda\\lib\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in g:\\anaconda\\lib\\site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in g:\\anaconda\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: colorama in g:\\anaconda\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Requirement already satisfied: paper-qa in g:\\anaconda\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: faiss-cpu in g:\\anaconda\\lib\\site-packages (from paper-qa) (1.7.4)\n",
      "Requirement already satisfied: pypdf in g:\\anaconda\\lib\\site-packages (from paper-qa) (3.14.0)\n",
      "Requirement already satisfied: PyCryptodome in g:\\anaconda\\lib\\site-packages (from paper-qa) (3.18.0)\n",
      "Requirement already satisfied: html2text in g:\\anaconda\\lib\\site-packages (from paper-qa) (2020.1.16)\n",
      "Requirement already satisfied: openai>=0.27.8 in g:\\anaconda\\lib\\site-packages (from paper-qa) (0.27.8)\n",
      "Requirement already satisfied: langchain>=0.0.198 in g:\\anaconda\\lib\\site-packages (from paper-qa) (0.0.252)\n",
      "Requirement already satisfied: tiktoken>=0.4.0 in g:\\anaconda\\lib\\site-packages (from paper-qa) (0.4.0)\n",
      "Requirement already satisfied: requests<3,>=2 in g:\\anaconda\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (2.28.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in g:\\anaconda\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (8.2.2)\n",
      "Requirement already satisfied: pydantic<2,>=1 in g:\\anaconda\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (1.10.12)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in g:\\anaconda\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (4.0.2)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in g:\\anaconda\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (0.0.19)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in g:\\anaconda\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (1.4.39)\n",
      "Requirement already satisfied: numpy<2,>=1 in g:\\anaconda\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (1.23.5)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in g:\\anaconda\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (1.2.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in g:\\anaconda\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (6.0)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in g:\\anaconda\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (2.8.4)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in g:\\anaconda\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (0.5.14)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in g:\\anaconda\\lib\\site-packages (from langchain>=0.0.198->paper-qa) (3.8.5)\n",
      "Requirement already satisfied: tqdm in g:\\anaconda\\lib\\site-packages (from openai>=0.27.8->paper-qa) (4.64.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in g:\\anaconda\\lib\\site-packages (from tiktoken>=0.4.0->paper-qa) (2022.7.9)\n",
      "Requirement already satisfied: attrs>=17.3.0 in g:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in g:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in g:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (1.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in g:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in g:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in g:\\anaconda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.198->paper-qa) (1.4.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in g:\\anaconda\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in g:\\anaconda\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in g:\\anaconda\\lib\\site-packages (from pydantic<2,>=1->langchain>=0.0.198->paper-qa) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in g:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain>=0.0.198->paper-qa) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in g:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain>=0.0.198->paper-qa) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in g:\\anaconda\\lib\\site-packages (from requests<3,>=2->langchain>=0.0.198->paper-qa) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in g:\\anaconda\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.0.198->paper-qa) (2.0.1)\n",
      "Requirement already satisfied: colorama in g:\\anaconda\\lib\\site-packages (from tqdm->openai>=0.27.8->paper-qa) (0.4.6)\n",
      "Requirement already satisfied: packaging>=17.0 in g:\\anaconda\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (22.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in g:\\anaconda\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.198->paper-qa) (0.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install thirdai --upgrade\n",
    "!pip3 install thirdai[neural_db]\n",
    "!pip3 install langchain --upgrade\n",
    "!pip3 install openai --upgrade\n",
    "!pip3 install paper-qa --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thirdai import licensing, neural_db as ndb\n",
    "licensing.activate('1FB7DD-CAC3EC-832A67-84208D-C4E39E-V3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's import the relevant module and define a neural db class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = ndb.NeuralDB(user_id=\"my_user\") # you can use any username, in the future, this username will let you push models to the model hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You even load from a base DB from our Bazaar (optional but recommended)\n",
    "\n",
    "We have a model bazaar that provides users with domain specific NeuralDBs that can jumpstart searching on their private documents. The Bazaar has two main types of DBs\n",
    "\n",
    "1. Base DBs: These come with models that have either general QnA capabilities or domain specific capabilities like search on Medical Documents, Financial documents or Contracts. These come with an empty data index into which users can insert their files.\n",
    "\n",
    "2. Pre-Indexed DBs: These are ready-to-search DBs that come with pre-trained models and their corresponding datasets. These are meant to  search through large public datasets like PubMed or Amazon 3MM Products or Stackoverflow issues etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a cache directory\n",
    "import os\n",
    "if not os.path.isdir(\"bazaar_cache\"):\n",
    "    os.mkdir(\"bazaar_cache\")\n",
    "\n",
    "from pathlib import Path\n",
    "from thirdai.neural_db import Bazaar\n",
    "bazaar = Bazaar(cache_dir=Path(\"bazaar_cache\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call fetch to refresh list of available DBs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bazaar.fetch() # Optional arg filter=\"model name\" to filter by model name.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the list of all DBs in the Bazaar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Contract Review', 'Finance QnA', 'General QnA']\n"
     ]
    }
   ],
   "source": [
    "print(bazaar.list_model_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ndb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally load the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = bazaar.get_model(\"General QnA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert your files\n",
    "\n",
    "Let's insert things into it!\n",
    "\n",
    "Currently, we natively support adding CSV, PDF and DOCX files. We also have a support to automatically scrape and parse URLs. All other file formats have to be converted into CSV files where each row represents a paragraph/text-chunk of the document. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example : CSV files\n",
    "The first example below shows how to insert a CSV file. Please note that a CSV file is required to have a column named \"DOC_ID\" with rows numbered from 0 to n_rows-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "insertable_docs = []\n",
    "csv_files = ['C:\\\\Users\\\\aryan\\\\OneDrive\\\\Documents\\\\DATA SCIENCE\\\\THIRDAI HACKATHON\\\\cleaned_data_final.csv']\n",
    "\n",
    "for file in csv_files:\n",
    "    csv_doc = ndb.CSV(\n",
    "        path=file,\n",
    "        id_column=\"DOC_ID\",\n",
    "        strong_columns=[\"text\"],\n",
    "        weak_columns=[\"user_name\"],  \n",
    "        reference_columns=[\"user_name\"])\n",
    "    #\n",
    "    insertable_docs.append(csv_doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command is intended to be used with a base DB which already has reasonable knowledge of the domain. In general, we always recommend using 'train=True' as shown below.\n",
    "\n",
    "#### Insert and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ids = db.insert(insertable_docs, train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you call the insert() method multiple times, the documents will automatically be de-duplicated. If insert=True, then the training will be done multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search\n",
    "\n",
    "Now let's start searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = db.search(\n",
    "    query=\"\",\n",
    "    top_k=2,\n",
    "    on_error=lambda error_msg: print(f\"Error! {error_msg}\"))\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.text)\n",
    "    # print(result.context(radius=1))\n",
    "    # print(result.source)\n",
    "    # print(result.metadata)\n",
    "    print('************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = db.search(\n",
    "    query=\"\",\n",
    "    top_k=2,\n",
    "    on_error=lambda error_msg: print(f\"Error! {error_msg}\"))\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.text)\n",
    "    # print(result.context(radius=1))\n",
    "    # print(result.source)\n",
    "    # print(result.metadata)\n",
    "    print('************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = db.search(\n",
    "    query=\"COVID Update: The infection rate in Florida is following the natural curve that experts predicted if the initial cu https://t.co/hmEwE747WK\",\n",
    "    top_k=2,\n",
    "    on_error=lambda error_msg: print(f\"Error! {error_msg}\"))\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.text)\n",
    "    print(result.context(radius=1))\n",
    "    print(result.source)\n",
    "    print(result.metadata)\n",
    "    print('************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RLHF\n",
    "\n",
    "Let's go over some of NeuralDB's advanced features. The first one is text-to-text association. This allows you to teach the model that two keywords, phrases, or concepts are related.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.associate(source=\"Plasma Bank at Sawai Man Singh Hospital in Jaipur\", target=\"DailyaddaaNews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's search again with the same query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = db.search(\n",
    "    query=\"Sawai Man Singh Hospital what happened there?\",\n",
    "    top_k=2,\n",
    ")\n",
    "\n",
    "for result in search_results:\n",
    "    print(result.text)\n",
    "    print(result.source)\n",
    "    print(result.metadata)\n",
    "    print('************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you go! In just a line, you taught the model to correct itself and retrieve the correct result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.text_to_result(\"Plasma Bank at Sawai Man Singh Hospital in Jaipur\",14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Answers from OpenAI using Langchain\n",
    "\n",
    "In this section, we will show how to use LangChain and query OpenAI's QnA module to generate an answer from the references that you retrieve from the above DB. You'll have to specify your own OpenAI key for this module to work. You can replace this segment with any other generative model of your choice. You can choose to use an source model like MPT or Dolly for answer generation with the same prompt that you use with OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from paperqa.prompts import qa_prompt\n",
    "from paperqa.chains import make_chain\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name='gpt-3.5-turbo', \n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "qa_chain = make_chain(prompt=qa_prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_references(query):\n",
    "    search_results = db.search(query,top_k=3)\n",
    "    references = []\n",
    "    for result in search_results:\n",
    "        references.append(result.text)\n",
    "    return references\n",
    "\n",
    "def get_answer(query, references):\n",
    "    return qa_chain.run(question=query, context='\\n\\n'.join(references[:3]), answer_length=\"abt 50 words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\n",
    "\n",
    "references = get_references(query)\n",
    "print(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "answer = get_answer(query, references)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Save\n",
    "As usual, saving and loading the DB are one-liners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your db\n",
    "db.save(\"sample_nda.db\")\n",
    "\n",
    "# Loading is just like we showed above, with an optional progress handler\n",
    "db.from_checkpoint(\"sample_nda.db\", on_progress=lambda fraction: print(f\"{fraction}% done with loading.\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
